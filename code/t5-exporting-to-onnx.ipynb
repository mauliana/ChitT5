{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"9L5w2xheiDq1"},"source":["## Converting fine-tuned model to onnx format with fastt5 library \n","\n","*   the library can be downloaded from [pypi.org](https://pypi.org/project/fastt5/) and [Github code](https://github.com/Ki6an/fastT5)\n","*   It convert the model and quantized it to decrease the model size and speed-up the inference time. However, this quantization will slightly reduce the accuracy.\n","*   works on torch ` 1.13.1 `\n","\n","\n","Note : it cannot be used if there is `nan` in the saved model weight "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4101,"status":"ok","timestamp":1677235661972,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"YmAEzQAlyv5I","outputId":"f93fab07-2690-4f7d-c2ae-c1fdd2ccce32"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.13.1+cu116\n"]}],"source":["import torch\n","\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17351,"status":"ok","timestamp":1677235681979,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"rDk8yaCA4Dcp","outputId":"7da14428-b56e-4cdb-94e3-afebf005733b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23736,"status":"ok","timestamp":1677235705705,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"o66LJF64iXrQ","outputId":"eac27fe3-9d04-4033-c7ac-2a5e6e048753"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastt5\n","  Downloading fastt5-0.1.4.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch!=1.8.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from fastt5) (1.13.1+cu116)\n","Collecting onnx\n","  Downloading onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime==1.10.0\n","  Downloading onnxruntime-1.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers>4.6.1\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting progress>=1.5\n","  Downloading progress-1.6.tar.gz (7.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from fastt5) (5.4.8)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime==1.10.0->fastt5) (1.22.4)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime==1.10.0->fastt5) (23.1.21)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime==1.10.0->fastt5) (3.19.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.8.0,>=1.7.0->fastt5) (4.5.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>4.6.1->fastt5) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>4.6.1->fastt5) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers>4.6.1->fastt5) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>4.6.1->fastt5) (3.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>4.6.1->fastt5) (23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>4.6.1->fastt5) (2022.6.2)\n","Collecting protobuf\n","  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>4.6.1->fastt5) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>4.6.1->fastt5) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>4.6.1->fastt5) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>4.6.1->fastt5) (1.24.3)\n","Building wheels for collected packages: fastt5, progress\n","  Building wheel for fastt5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastt5: filename=fastt5-0.1.4-py3-none-any.whl size=16526 sha256=b49a8b8434845cb3057bf7e2e5927d0fc0749bb6881d34627baccf14201df809\n","  Stored in directory: /root/.cache/pip/wheels/f3/9e/1a/5fdc7a116818977cc31927652e0b0e18598c0b69d60baa60db\n","  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9630 sha256=b509682483b9a676f05e1bc8bd1568f8f3267d7760610dab5df655b1666be9db\n","  Stored in directory: /root/.cache/pip/wheels/bb/01/5a/c916509df9b12c6465864251dbe826def8e31a16fa7da54f08\n","Successfully built fastt5 progress\n","Installing collected packages: tokenizers, sentencepiece, progress, protobuf, onnxruntime, onnx, huggingface-hub, transformers, fastt5\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.6\n","    Uninstalling protobuf-3.19.6:\n","      Successfully uninstalled protobuf-3.19.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fastt5-0.1.4 huggingface-hub-0.12.1 onnx-1.13.1 onnxruntime-1.10.0 progress-1.6 protobuf-3.20.3 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":[" !pip install fastt5"]},{"cell_type":"markdown","metadata":{"id":"bZIKfZEdPRfS"},"source":["Exporting to ONNX"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317387,"status":"ok","timestamp":1677236032448,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"vOmGLOo2iHcH","outputId":"9410f99d-e177-444f-85c5-ac582a65ff47"},"outputs":[{"name":"stderr","output_type":"stream","text":["Exporting to onnx... |################################| 3/3\n","Quantizing... |################################| 3/3\n","\u001b[?25h"]},{"name":"stdout","output_type":"stream","text":["Setting up onnx model...\n","Done!\n"]}],"source":["from fastT5 import export_and_get_onnx_model\n","\n","# model_name = 't5-small'\n","model_path = 'drive/MyDrive/t5-model/t5'\n","model = export_and_get_onnx_model(model_path)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1900,"status":"ok","timestamp":1677236465991,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"ziaxQUp8ic40","outputId":"55d5425f-65cb-479c-a33a-843b8fd36fff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Don't you know that?\n"]}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","t_input = \"generate question: The universe is a dark forest.\"\n","token = tokenizer(t_input, return_tensors='pt')\n","\n","tokens = model.generate(input_ids=token['input_ids'],\n","               attention_mask=token['attention_mask'],\n","               num_beams=2)\n","\n","output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)\n","print(output)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":672,"status":"ok","timestamp":1677236469539,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"sRBOZUhgGooF"},"outputs":[],"source":["from transformers import T5Config\n","\n","config = T5Config.from_pretrained(model_path)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1677236472571,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"fa5lbMu3E7K8"},"outputs":[],"source":["tokenizer.save_pretrained('models/')\n","config.save_pretrained('models/')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1677236476696,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"3ZMAh5BYHnhg","outputId":"260d3475-2e3e-4ade-e732-54825dbcc0be"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0G\tmodels\n"]}],"source":["!du -sh models"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4050,"status":"ok","timestamp":1677236545394,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"zfHOD4wlIfuF"},"outputs":[],"source":["!cp -r models '/content/drive/My Drive/t5-model/onnx-model'"]},{"cell_type":"markdown","metadata":{"id":"M7x4R0sPO_WW"},"source":["ONNX Inference"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":15111,"status":"ok","timestamp":1677236568906,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"jyTH2luF4mfO"},"outputs":[],"source":["from fastT5 import get_onnx_model, get_onnx_runtime_sessions, OnnxT5\n","from transformers import AutoTokenizer\n","from pathlib import Path\n","import os\n","\n","# onnx_model_path = 'models'\n","onnx_model_path = 'drive/MyDrive/t5-model/onnx-model/models'\n","onnx_model_name = Path('t5').stem\n","\n","encoder_path = os.path.join(onnx_model_path, f\"{onnx_model_name}-encoder-quantized.onnx\")\n","decoder_path = os.path.join(onnx_model_path, f\"{onnx_model_name}-decoder-quantized.onnx\")\n","init_decoder_path = os.path.join(onnx_model_path, f\"{onnx_model_name}-init-decoder-quantized.onnx\")\n","\n","model_paths = encoder_path, decoder_path, init_decoder_path\n","model_sessions = get_onnx_runtime_sessions(model_paths)\n","model = OnnxT5(onnx_model_path, model_sessions)\n","\n","tokenizer = AutoTokenizer.from_pretrained(onnx_model_path)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548,"status":"ok","timestamp":1677236575402,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"DJvFWt8aLdkm","outputId":"8b711604-1fac-4638-fef8-23d85e1c0e2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["I hope it stays nice like this.\n","CPU times: user 279 ms, sys: 0 ns, total: 279 ms\n","Wall time: 286 ms\n"]}],"source":["%%time\n","# text = \"I need to leave now. What time do you need to leave? at 2 o'clock\"\n","text = \"It's a lovely day\"\n","inputs = tokenizer(\"generate question: \"+text, return_tensors=\"pt\").input_ids\n","outputs = model.generate(\n","    inputs, \n","    num_beams=3, \n","    max_length=100, \n","    early_stopping=True, \n","    num_return_sequences=1)\n","\n","response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dD0c3FrpMLGD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mv16Q9c_ubM6"},"outputs":[],"source":["# ls drive/MyDrive/t5-finetuned/onnx-model/models"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1008,"status":"ok","timestamp":1677236495103,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"U6Pz_wbj4rkS"},"outputs":[],"source":["rm -f -r models/*decoder.onnx"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":699,"status":"ok","timestamp":1677236497444,"user":{"displayName":"mauliana","userId":"17520362335611971041"},"user_tz":-60},"id":"jyG3wCasC8Nc"},"outputs":[],"source":["rm -f -r models/*encoder.onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NzGbgI0no9m"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1HuH1Ui3pCBS22hW4djIOyUBP5UW93705","timestamp":1675286293279}]},"gpuClass":"standard","kernelspec":{"display_name":"ml","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13"},"vscode":{"interpreter":{"hash":"ae3a811fad1b8ed3af2b1b1fa89ca0c4adf3d6da83d1ef129e35d8ecd2ca7004"}}},"nbformat":4,"nbformat_minor":0}
